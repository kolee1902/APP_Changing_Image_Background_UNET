{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 🔍 **Framework Project: Change Background Image using U-Net**\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 1. Giới thiệu\n",
        "\n",
        "Trong lĩnh vực xử lý ảnh, đặc biệt là bài toán **phân đoạn ảnh (image segmentation)**, việc tách tiền cảnh (foreground) khỏi hậu cảnh (background) là một bước quan trọng. Kiến trúc **U-Net**, được giới thiệu lần đầu trong lĩnh vực ảnh sinh học, đã chứng minh hiệu quả vượt trội cho các bài toán segmentation mà không cần một lượng lớn dữ liệu huấn luyện.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 2. Kiến trúc U-Net\n",
        "\n",
        "Kiến trúc U-Net gồm ba thành phần chính:\n",
        "\n",
        "* **Encoder (Contracting Path)**: Trích xuất đặc trưng với các lớp tích chập (convolution) và giảm kích thước (max pooling).\n",
        "* **Decoder (Expanding Path)**: Tăng kích thước ảnh đầu ra bằng các lớp up-convolution (deconvolution) để tái tạo lại phân vùng ảnh.\n",
        "* **Skip Connections**: Giúp giữ lại thông tin chi tiết (ví dụ: biên ảnh) bằng cách kết nối trực tiếp encoder với decoder tại các tầng tương ứng.\n",
        "* **1x1 Convolution cuối cùng**: Dự đoán phân lớp trên từng pixel.\n",
        "\n",
        "```\n",
        "Encoder (↓):        Input -> Conv -> ReLU -> Conv -> ReLU -> MaxPool\n",
        "Decoder (↑):        UpConv -> Concatenate (skip) -> Conv -> ReLU -> Conv -> ReLU\n",
        "```\n",
        "\n",
        "### 🔧 Cấu trúc tổng quát\n",
        "\n",
        "\n",
        "![Ảnh minh hoạ](https://media.geeksforgeeks.org/wp-content/uploads/20220614121231/Group14.jpg)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 🧱 Kiến trúc chi tiết\n",
        "\n",
        "| Thành phần     | Chi tiết                                          |\n",
        "| -------------- | ------------------------------------------------- |\n",
        "| Conv layers    | 3x3 padding + ReLU                                |\n",
        "| MaxPooling     | 2x2                                               |\n",
        "| Up-convolution | 2x2                                               |\n",
        "| Output layer   | 1x1 convolution để dự đoán phân lớp tại mỗi pixel |\n",
        "\n",
        "U-Net sử dụng **data augmentation mạnh mẽ** (flip, rotation, shift, elastic deformation) để tạo ra nhiều mẫu từ ảnh gốc – điều này giúp giải quyết vấn đề thiếu dữ liệu.\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ 3. Ứng dụng U-Net cho Project Change Background\n",
        "\n",
        "### 🎯 Mục tiêu\n",
        "\n",
        "Sử dụng U-Net để **tách lớp foreground (người, vật thể chính)** khỏi ảnh, sau đó **thay thế background** bằng một ảnh mới.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔧 Framework tổng quan\n",
        "\n",
        "---\n",
        "\n",
        "### 🚶‍♂️ Bước 1: Chuẩn bị Dữ liệu\n",
        "\n",
        "* **Input**: Hình ảnh RGB chứa người hoặc vật thể chính cần giữ lại.\n",
        "* **Resize** ảnh về kích thước cố định (thường là `256x256`).\n",
        "* **Normalize** pixel trong khoảng `[0, 1]`.\n",
        "\n",
        "---\n",
        "\n",
        "### 🧠 Bước 2: Dự đoán Mask bằng U-Net\n",
        "\n",
        "* Mô hình U-Net được **load từ trọng số đã huấn luyện** hoặc **huấn luyện lại** từ đầu (nếu dữ liệu đủ).\n",
        "* Output là một **binary mask**, nơi `1` tương ứng với foreground (người), `0` là background.\n",
        "\n",
        "---\n",
        "\n",
        "### 🧪 Bước 3: Hậu xử lý Mask\n",
        "\n",
        "* **Làm mịn mask** bằng các kỹ thuật như:\n",
        "\n",
        "  * Morphological operation (erosion/dilation)\n",
        "  * Gaussian blur\n",
        "  * Thresholding\n",
        "\n",
        "> Mục đích: Tăng độ chính xác biên và giảm nhiễu.\n",
        "\n",
        "---\n",
        "\n",
        "### ✂️ Bước 4: Tách foreground\n",
        "\n",
        "Sử dụng mask để giữ lại vùng foreground:\n",
        "\n",
        "```python\n",
        "result = input_image * mask[..., np.newaxis]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 🌄 Bước 5: Chèn nền mới\n",
        "\n",
        "* Load ảnh nền mới (có cùng kích thước).\n",
        "* Áp dụng công thức:\n",
        "\n",
        "```python\n",
        "output = result + background * (1 - mask[..., np.newaxis])\n",
        "```\n",
        "\n",
        "* Kết quả là một ảnh mới với foreground giữ nguyên và background đã thay đổi.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 4. Đánh giá\n",
        "\n",
        "Nhóm chạy cùng một mô hình với dữ liệu đầu vào giống nhau cho cả phiên bản tuần tự và phiên bản song song (dùng multiprocessing). Sau đó, nhóm so sánh độ chính xác (accuracy) của hai mô hình.\n",
        "\n",
        "Ngoài ra, nhóm có thể sử dụng các tiêu chí đánh giá phổ biến:\n",
        "\n",
        "| Chỉ số             | Giải thích                                          |\n",
        "| ------------------ | --------------------------------------------------- |\n",
        "| **IoU**            | Mức độ chồng lấp giữa mask dự đoán và ground truth  |\n",
        "| **Dice Score**     | Tỷ lệ chính xác giữa vùng foreground được phân đoạn |\n",
        "| **Pixel Accuracy** | Tỷ lệ pixel được phân loại đúng                     |\n",
        "\n",
        "## 📌 5. Vì sao lại lựa chọn U-Net?\n",
        "\n",
        "U-Net là một mô hình mạnh mẽ và đơn giản cho bài toán segmentation. Khi áp dụng vào project thay background ảnh:\n",
        "\n",
        "* Mô hình có thể tách chính xác foreground, giúp thay background mượt mà.\n",
        "* Có thể kết hợp thêm các kỹ thuật xử lý ảnh cổ điển để cải thiện đầu ra.\n",
        "* U-Net pretrained có thể dùng với các tập dữ liệu segmentation thông dụng như COCO, Pascal VOC, hoặc tự thu thập nếu phù hợp.\n",
        "\n",
        "---\n",
        "\n",
        "## 📚 Tham khảo\n",
        "\n",
        "* Ronneberger et al., *U-Net: Convolutional Networks for Biomedical Image Segmentation*, [arXiv:1505.04597](https://arxiv.org/pdf/1505.04597v1)\n",
        "* [https://towardsdatascience.com/understanding-u-net-61276b10f360/](https://towardsdatascience.com/understanding-u-net-61276b10f360/)\n",
        "* [https://github.com/milesial/Pytorch-UNet](https://github.com/milesial/Pytorch-UNet)\n"
      ],
      "metadata": {
        "id": "1S0pLLYFnPIz"
      }
    }
  ]
}